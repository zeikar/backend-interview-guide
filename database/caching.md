# 캐싱 (Caching)

## 목차

- [캐싱](#캐싱)
- [캐시의 유형](#캐시의-유형)
  - [클라이언트 측 캐시(Client-side Cache)](#클라이언트-측-캐시client-side-cache)
  - [서버 측 캐시(Server-side Cache)](#서버-측-캐시server-side-cache)
  - [역방향 프록시 캐시(Reverse Proxy Cache)](#역방향-프록시-캐시reverse-proxy-cache)
  - [CDN 캐시(Content Delivery Network Cache)](#cdn-캐시content-delivery-network-cache)
- [캐시 적중률(Cache Hit Ratio)](#캐시-적중률cache-hit-ratio)
  - [캐시 적중률 계산](#캐시-적중률-계산)
  - [캐시 적중률을 높이기 위한 전략](#캐시-적중률을-높이기-위한-전략)
- [캐시 무효화(Cache Invalidation)](#캐시-무효화cache-invalidation)
  - [캐시 무효화 전략](#캐시-무효화-전략)
- [캐시 갱신 전략](#캐시-갱신-전략)
  - [Write-Through 캐시](#write-through-캐시)
  - [Write-Behind (Write-Back) 캐시](#write-behind-write-back-캐시)
  - [Write-Around 캐시](#write-around-캐시)
- [캐시의 문제점](#캐시의-문제점)
  - [캐시 일관성 문제(Cache Inconsistency)](#캐시-일관성-문제cache-inconsistency)
  - [캐시 스탬피드(Cache Stampede)](#캐시-스탬피드-cache-stampede)
  - [캐시 과부하(Cache Overload)](#캐시-과부하cache-overload)
  - [캐시 독립성(Cache Dependency)](#캐시-독립성cache-dependency)
  - [네트워크 지연(Network Latency)](#네트워크-지연network-latency)

# 캐싱

캐시는 데이터를 더 빠르게 접근할 수 있는 위치에 저장하여 시스템의 성능을 향상시키는 기술입니다. 일반적으로 메모리와 같은 고속 스토리지에 자주 사용되는 데이터를 저장함으로써, 데이터베이스나 원격 서버에서 데이터를 가져오는 시간을 줄입니다. 캐시는 주로 다음과 같은 이유로 데이터베이스 시스템에서 중요합니다:

- **성능 향상:** 캐시는 데이터베이스에 직접 접근하는 횟수를 줄여 데이터 접근 시간을 단축시킵니다. 이는 특히 읽기 요청이 많은 시스템에서 중요합니다.
- **부하 감소:** 데이터베이스에 가해지는 부하를 줄여, 더 많은 사용자 요청을 처리할 수 있도록 합니다. 이를 통해 데이터베이스의 리소스 사용을 최적화하고, 성능 병목현상을 완화합니다.
- **비용 절감:** 데이터베이스 서버의 부하를 줄이므로, 추가적인 서버 자원을 필요로 하는 상황을 줄이고, 비용을 절감할 수 있습니다.

캐시는 주로 자주 접근되는 데이터(예: 인기 있는 상품 목록, 사용자의 세션 정보 등)에 대해 사용되며, 이러한 데이터는 데이터베이스보다 훨씬 빠르게 접근 가능합니다. 따라서 캐시를 올바르게 설정하면 애플리케이션의 전체적인 성능이 크게 향상됩니다.

# 캐시의 유형

캐시는 시스템의 아키텍처와 필요에 따라 다양한 유형으로 구현될 수 있습니다. 주요 캐시 유형은 다음과 같습니다:

## 클라이언트 측 캐시(Client-side Cache)

- **설명:** 웹 브라우저나 애플리케이션의 로컬 스토리지에 데이터를 저장하여, 서버에 요청하지 않고도 데이터를 빠르게 접근할 수 있도록 합니다. 예: 브라우저 캐시, 로컬 스토리지.
- **장점:** 서버 부하를 줄이고, 네트워크 지연을 감소시켜 빠른 응답 시간을 제공합니다.
- **단점:** 클라이언트 환경에 따라 데이터가 손실될 수 있으며, 캐시된 데이터의 일관성을 보장하기 어렵습니다.

## 서버 측 캐시(Server-side Cache)

- **설명:** 서버에서 자주 사용되는 데이터를 메모리나 디스크에 저장하여, 데이터베이스 조회를 줄입니다. 예: Redis, Memcached.
- **장점:** 빠른 데이터 접근이 가능하며, 서버 측에서 일관성을 보다 쉽게 관리할 수 있습니다.
- **단점:** 서버 리소스를 추가로 사용하며, 캐시의 크기가 제한될 수 있습니다.

## 역방향 프록시 캐시(Reverse Proxy Cache)

- **설명:** 웹 서버 앞단에 캐시 서버를 배치하여 클라이언트 요청을 캐시된 콘텐츠로 응답합니다. 예: Varnish, Nginx 캐시.
- **장점:** 웹 서버 부하를 크게 줄이고, 콘텐츠 제공 속도를 높일 수 있습니다.
- **단점:** 캐시 무효화 정책을 적절히 설정하지 않으면, 오래된 데이터를 제공할 위험이 있습니다.

## CDN 캐시(Content Delivery Network Cache)

- **설명:** 전 세계에 분산된 캐시 서버에 콘텐츠를 저장하여, 사용자에게 지리적으로 가까운 서버에서 콘텐츠를 제공합니다.
- **장점:** 전송 지연을 줄이고, 전 세계적으로 빠른 콘텐츠 제공을 보장합니다.
- **단점:** 설정이 복잡할 수 있으며, 비용이 발생합니다.

# 캐시 적중률(Cache Hit Ratio)

캐시 적중률(Cache Hit Ratio)은 캐시에 대한 전체 요청 중 캐시에서 데이터를 성공적으로 제공한 비율을 의미합니다. 이는 캐시의 효율성을 측정하는 중요한 지표로, 높은 적중률은 캐시가 효과적으로 작동하고 있음을 나타냅니다.

## 캐시 적중률 계산

캐시 적중률 = (캐시 히트 수 / 캐시 요청 수) × 100%

## 캐시 적중률을 높이기 위한 전략

- **적절한 캐시 키 설정:** 캐시 키는 저장된 데이터를 식별하는 데 사용되며, 적절한 캐시 키를 설정하여 중복된 데이터가 캐시에 저장되지 않도록 해야 합니다. 캐시 키의 충돌을 최소화하여 적중률을 높일 수 있습니다.
- **캐시된 데이터의 TTL(Time to Live) 설정 최적화:** TTL은 캐시에 저장된 데이터가 유효한 시간을 지정하며, 적절한 TTL을 설정하면 데이터가 너무 자주 무효화되지 않아 적중률을 높일 수 있습니다.
- **프리페칭(Pre-fetching):** 예상되는 데이터를 미리 캐시에 로드하여, 이후 요청에 대해 캐시 적중률을 높일 수 있습니다. 예를 들어, 사용자가 자주 방문하는 페이지를 미리 캐싱해두는 방법이 있습니다.
- **캐시 크기 조정:** 캐시의 크기를 적절하게 조정하여 더 많은 데이터를 캐시에 저장할 수 있도록 합니다. 이를 통해 데이터베이스나 원본 서버에 대한 접근 빈도를 줄이고, 적중률을 높일 수 있습니다.
- **자주 사용되는 데이터 우선 캐싱:** 자주 액세스되는 데이터를 우선적으로 캐시에 저장하고, 드물게 사용되는 데이터는 캐싱하지 않거나, 우선순위를 낮추는 방법으로 적중률을 높일 수 있습니다.
- **LRU(Least Recently Used) 알고리즘 사용:** 자주 사용되지 않는 데이터를 캐시에서 제거하고, 새로운 데이터를 추가하는 캐시 교체 알고리즘을 사용하여 최신 데이터의 적중률을 높입니다. LRU 알고리즘은 메모리 효율성을 유지하면서 적중률을 최적화하는 데 효과적입니다.

# 캐시 무효화(Cache Invalidation)

캐시 무효화(Cache Invalidation)는 캐시에 저장된 데이터가 더 이상 유효하지 않을 때, 이를 제거하거나 갱신하는 과정입니다. 이는 일관성 문제를 방지하기 위해 중요합니다. 캐시에 저장된 데이터가 오래된 상태로 남아 있으면, 사용자가 잘못된 정보를 얻을 수 있기 때문에, 적절한 무효화 전략이 필요합니다.

## 캐시 무효화 전략

- **수동 무효화(Manual Invalidation):** 애플리케이션 로직에서 특정 이벤트가 발생할 때 명시적으로 캐시를 무효화합니다. 예를 들어, 데이터베이스에서 업데이트가 발생하면 해당 캐시 키를 삭제하는 방식입니다.
  - **장점:** 필요한 시점에 정확하게 캐시를 무효화할 수 있습니다.
  - **단점:** 복잡한 애플리케이션 로직에서 오류가 발생할 수 있으며, 유지보수가 어렵습니다.
- **TTL 기반 무효화(Time-based Invalidation):** 캐시에 저장된 데이터에 TTL을 설정하여 일정 시간이 지나면 자동으로 무효화되도록 합니다.
  - **장점:** 자동으로 캐시를 무효화하여, 일관성을 유지하기 쉽습니다.
  - **단점:** TTL이 너무 짧으면 캐시 적중률이 낮아지고, 너무 길면 오래된 데이터가 남아 있을 수 있습니다.
- **LRU 알고리즘(Least Recently Used):** 자주 사용되지 않는 데이터를 우선적으로 제거하여 새로운 데이터를 캐시에 추가하는 방식입니다.
  - **장점:** 메모리 자원을 효율적으로 사용하면서 최신 데이터의 적중률을 유지할 수 있습니다.
  - **단점:** 오래된 데이터를 제거하는 데 있어 최신 데이터가 항상 중요하지 않을 수 있습니다.

# 캐시 갱신 전략

캐시 갱신은 데이터 일관성을 유지하기 위해 매우 중요한 부분입니다. 캐시에서 데이터를 갱신하는 방식에는 여러 가지가 있으며, 각각의 방식은 시스템 요구사항에 따라 적합성이 달라집니다. 여기서는 Write-Through, Write-Behind, Write-Around 등 주요 캐시 갱신 전략을 자세히 설명하겠습니다.

## Write-Through 캐시

### 설명

Write-Through 캐시 전략에서는 데이터가 캐시에 기록될 때, 동시에 데이터베이스(또는 원본 스토리지)에도 즉시 기록됩니다. 이 방법은 데이터 일관성을 보장하는 가장 간단하고 직관적인 방법 중 하나입니다.

### 동작 방식

- 사용자가 데이터를 업데이트하거나 삽입하면, 그 데이터는 먼저 캐시에 저장됩니다.
- 캐시에 저장된 데이터는 즉시 데이터베이스에도 동일하게 기록됩니다.
- 이 방식에서는 데이터베이스와 캐시가 항상 동일한 데이터를 유지합니다.

### 장점

- **데이터 일관성:** 캐시와 데이터베이스 간의 일관성을 즉시 보장할 수 있습니다. 어떤 시점에서든 캐시와 데이터베이스의 데이터가 동일하게 유지됩니다.
- **단순성:** 캐시가 업데이트되면 항상 데이터베이스도 업데이트되므로, 별도의 복잡한 일관성 관리 로직이 필요 없습니다.

### 단점

- **쓰기 성능 저하:** 데이터가 캐시와 데이터베이스 모두에 기록되기 때문에, 쓰기 작업의 지연 시간이 증가할 수 있습니다.
- **부하 증가:** 모든 쓰기 작업이 캐시와 데이터베이스에 동시에 이루어지기 때문에, 데이터베이스에 대한 부하가 줄어들지 않습니다.

### 사용 사례

- **데이터 일관성이 중요한 시스템:** 예를 들어, 금융 시스템이나 주문 처리 시스템 등에서는 데이터의 정확성이 매우 중요하므로, Write-Through 캐시가 적합할 수 있습니다.

## Write-Behind (Write-Back) 캐시

### 설명

Write-Behind 또는 Write-Back 캐시 전략에서는 데이터가 캐시에 기록되지만, 데이터베이스에 즉시 반영되지 않고 일정 시간 후에 비동기적으로 기록됩니다. 이 방식은 캐시의 쓰기 성능을 높이는 데 중점을 둡니다.

### 동작 방식

- 사용자가 데이터를 업데이트하면, 그 데이터는 캐시에 기록됩니다.
- 데이터베이스에는 즉시 기록되지 않으며, 배치(batch) 방식으로 일정 시간 후에 한 번에 기록됩니다.
- 이 시간 동안 캐시에는 최신 데이터가 있지만, 데이터베이스에는 아직 반영되지 않았을 수 있습니다.

### 장점

- **쓰기 성능 향상:** 데이터베이스에 대한 쓰기 작업이 지연되므로, 사용자 응답 시간이 빨라지고, 쓰기 성능이 향상됩니다.
- **데이터베이스 부하 감소:** 배치 처리 방식으로 여러 쓰기 작업을 한꺼번에 처리하기 때문에 데이터베이스에 대한 부하가 줄어듭니다.

### 단점

- **데이터 일관성 문제:** 데이터베이스와 캐시 간의 데이터 일관성이 즉시 유지되지 않기 때문에, 시스템 오류가 발생할 경우 데이터 손실 또는 불일치 문제가 발생할 수 있습니다.
- **복잡성:** 비동기적으로 데이터베이스를 갱신하기 때문에, 장애 발생 시 복구 절차가 복잡해질 수 있습니다.

### 사용 사례

- **쓰기 성능이 중요한 시스템:** 로그 데이터 수집, 통계 데이터 저장 등에서 적합합니다. 이 경우, 일시적인 데이터 불일치를 허용할 수 있으며, 성능 최적화가 더 중요한 시스템에서 사용됩니다.

## Write-Around 캐시

### 설명

Write-Around 캐시 전략에서는 쓰기 작업이 캐시에 직접 기록되지 않고, 데이터베이스에만 기록됩니다. 이후에 데이터가 필요할 때, 그때 캐시에서 데이터를 가져오게 됩니다. 이는 읽기 성능을 중시하는 시스템에서 주로 사용됩니다.

### 동작 방식

- 사용자가 데이터를 업데이트하면, 그 데이터는 캐시에 기록되지 않고, 데이터베이스에만 기록됩니다.
- 이후 해당 데이터에 대한 읽기 요청이 들어오면, 그때 캐시에 로드됩니다.
- 캐시는 주로 자주 조회되는 데이터를 저장하며, 쓰기 작업은 대부분 데이터베이스에서 처리됩니다.

### 장점

- **캐시 오염 방지:** 자주 사용되지 않는 데이터가 캐시에 기록되지 않으므로, 캐시 메모리를 효율적으로 사용할 수 있습니다.
- **쓰기 성능 최적화:** 캐시에 기록할 필요가 없기 때문에, 쓰기 작업의 성능이 향상됩니다.

### 단점

- **첫 번째 읽기 작업의 성능 저하:** 데이터가 캐시에 기록되지 않기 때문에, 첫 번째 읽기 작업은 데이터베이스에서 직접 수행되며, 이로 인해 초기 읽기 성능이 저하될 수 있습니다.
- **일관성 관리 필요:** 캐시에 기록되지 않은 데이터에 대한 읽기 작업이 들어올 때, 데이터베이스와의 일관성을 관리하기 위한 로직이 필요합니다.

### 사용 사례

- **읽기 요청이 매우 빈번한 시스템:** 캐시는 자주 접근되는 데이터에 대해 높은 성능을 제공하기 때문에, 읽기 작업이 많고 쓰기 작업이 상대적으로 적은 시스템에서 Write-Around 캐시 전략이 적합합니다.

# 캐시의 문제점

캐시는 성능 최적화에 큰 도움이 되지만, 잘못 설정하거나 관리하지 않으면 여러 문제가 발생할 수 있습니다. 주요 문제점과 해결 방법은 다음과 같습니다:

## 캐시 일관성 문제(Cache Inconsistency)

### 문제

데이터베이스와 캐시 사이에 데이터 불일치가 발생할 수 있으며, 이는 잘못된 정보를 제공하게 만듭니다.

### 해결 방법

캐시 무효화 전략을 적절히 설계하고, TTL 설정, 쓰기-스루, 쓰기-비하인드 캐시와 같은 일관성 유지 기법을 사용하여 문제를 최소화합니다.

## 캐시 스탬피드(Cache Stampede)

### 문제

캐시가 만료되거나 비워진 경우, 다수의 클라이언트가 동시에 데이터베이스에 접근하려고 할 때, 데이터베이스에 과부하가 발생하는 현상입니다.

### 해결 방법

랜덤하게 TTL을 설정하여 캐시 만료 시간을 분산시키거나, 잠금 메커니즘을 도입하여 한 번에 하나의 요청만이 데이터를 갱신하도록 합니다.

## 캐시 과부하(Cache Overload)

### 문제

캐시가 너무 많은 데이터를 저장하려고 하거나, 캐시에 대한 요청이 너무 많을 때 발생합니다. 이는 캐시 자체의 성능 저하를 초래할 수 있습니다.

### 해결 방법

캐시의 크기를 적절히 설정하고, LRU와 같은 효율적인 캐시 교체 알고리즘을 사용하여 자주 사용되지 않는 데이터를 제거합니다.

## 캐시 독립성(Cache Dependency)

### 문제

애플리케이션이 캐시에 지나치게 의존하게 되어, 캐시 장애 시 전체 시스템의 성능이 크게 저하될 수 있습니다.

### 해결 방법

캐시 장애를 대비한 적절한 폴백(Fallback) 메커니즘을 설계하고, 캐시가 사용 불가능할 때에도 시스템이 기능할 수 있도록 해야 합니다.

## 네트워크 지연(Network Latency)

### 문제

분산 캐시 시스템에서 네트워크 지연이 발생하여 캐시 접근 속도가 느려질 수 있습니다.

### 해결 방법

캐시 서버를 클라이언트에 가깝게 배치하거나, 데이터 센터 내에서 로컬 캐시를 사용하는 방법으로 네트워크 지연을 줄입니다.
